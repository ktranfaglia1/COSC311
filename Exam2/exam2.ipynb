{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Please use the \"breast cancer dataset\" included in the scikit-learn library to conduct the following tasks. \n",
    "\n",
    "Task 1: Randomly split this dataset into two parts: 60% for training and 40% for testing. Use KNN (k = 5) algorithm to conduct INDEPENDENT TEST, show the results using Classification Report;\n",
    "\n",
    "Task 2: Use the WHOLE dataset and Decision Tree algorithm (parameter setting: criterion is \"entropy\", max-depth is 15), conduct SELF TEST, show the test accuracy and draw the corresponding confusion matrix (in a figure);\n",
    "\n",
    "Task 3: Use the WHOLE dataset and SVC algorithm (parameter setting: C is 5, kernel is \"rbf\", gamma is 0.05), conduct a 5-fold cross validation test and show the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# Print the confusion matrix, classification report and accuracy score\n",
    "def printResults(targetTest, prediction):\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(targetTest, prediction))\n",
    "    print(\"Accuracy Score:\", accuracy_score(targetTest, prediction))\n",
    " \n",
    "\n",
    "# Task 1\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(dataset.data,columns=dataset.feature_names)\n",
    "df['target'] = pd.Series(dataset.target)\n",
    "\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    " \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.6, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(X_train)\n",
    "test_data_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, algorithm=\"brute\", weights='distance')\n",
    "\n",
    "knn_classifier.fit(train_data_scaled, y_train)\n",
    "\n",
    "knn_independent_test_predict = knn_classifier.predict(test_data_scaled)\n",
    "\n",
    "print(\"Independent test KNN Results:\")\n",
    "printResults(y_test, knn_independent_test_predict)  # knn results\n",
    "\n",
    "# Task 2\n",
    "self_test_data_scaled = scaler.fit_transform(X)\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=15)\n",
    "\n",
    "# Get predictions\n",
    "dt_self_test_predict = dt_classifier.predict(self_test_data_scaled)\n",
    "\n",
    "# Print results for self-test\n",
    "print(\"Self-test DT Results:\")\n",
    "printResults(y, dt_self_test_predict)  # dt results\n",
    "dtconfusionMatrix = confusion_matrix(y, dt_self_test_predict)\n",
    "print(\"\\nConfusion Matrix:\\n\", dtconfusionMatrix)\n",
    "# Display a heatmap using matplotlib and the sklearn toolset to display a confusion matrix\n",
    "matrixDisplay = ConfusionMatrixDisplay(confusion_matrix = dtconfusionMatrix)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Create layout and structure figure\n",
    "matrixDisplay.plot(ax = ax, cmap = 'Reds')  # Create Plot\n",
    "# Plot labels\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "# plt.savefig('confusion_matrix.png')  # Save plot as png\n",
    "plt.show()  # Display plot\n",
    "\n",
    "svc = SVC(kernel = 'rbf', C = 5, gamma = 0.05, random_state = 7)  # Instantiate an SVCClassifier object with optimized parameters\n",
    "\n",
    "# Implementing cross validation\n",
    "k = 5  # number of fold\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    " \n",
    "acc_score = []\n",
    " \n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "     \n",
    "    svc.fit(X_train, y_train)\n",
    "    pred_values = svc.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values, y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Please use the \"Iris Dataset\" included in the scikit-learn library to conduct the following clustering tasks. \n",
    "\n",
    "Task 1: Conduct PCA analysis on the dataset and find out how many principal components are needed to keep at least 95% variance (i.e. the ratio of variance loss, Î·, is less than 5%). Assume m principal components are needed, transform the dataset to m dimensions.\n",
    "\n",
    "Task 2: Using the transformed data, conduct k-means clustering (k = 3, each cluster is a type of iris plant),\n",
    "1) output the corresponding center of each cluster;\n",
    "2) output the clustering accuracy (i.e. out of all samples, how many samples are correctly identified);\n",
    "3) show the corresponding confusion matrix in a figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "# Standardize the matrix\n",
    "digits_mean = np.mean(X, axis=0)\n",
    "digits_std = np.std(X, axis=0)\n",
    "digits_std[digits_std == 0] = 1e-10  # Change stds of 0 to a small value to avoid division by zero\n",
    "digits_normalized = (X - digits_mean) / digits_std\n",
    "\n",
    "# Perform Principal Component Analysis (PCA) with normalized data\n",
    "pca_normalized = PCA(n_components=0.95)\n",
    "digits_data_new = pca_normalized.fit_transform(digits_normalized)\n",
    "\n",
    "# Get the covariance matrix with normalized data\n",
    "covariance_matrix = pca_normalized.get_covariance()\n",
    "\n",
    "# Dsiplay covariance matrix with normalized data\n",
    "print(\"PCA Analysis with normalized data\")\n",
    "print(\"Covariance Matrix:\")\n",
    "print(covariance_matrix)\n",
    "\n",
    "# Number of principal components required to keep at least 95% variance with normalized data\n",
    "print(\"Percentage of variance explained by each component to the total variance:\\n\", pca_normalized.explained_variance_ratio_)\n",
    "print(f\"Total explained variance ratio: {np.sum(pca_normalized.explained_variance_ratio_):.2f}\")\n",
    "print(f\"Number of principal components to keep at least 95% variance: {pca_normalized.n_components_}\")\n",
    "\n",
    "# Perform PCA\n",
    "pca_final = PCA(n_components=pca_normalized.n_components_)\n",
    "digits_data_transformed = pca_final.fit_transform(digits_normalized)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data_transformed, y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Initialize the KNeighborsClassifier object\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=4)  # Use number of samples in the training set as neighbors\n",
    "\n",
    "# Fit the model to the training data using the actual target labels\n",
    "knn_pca.fit(X_train, y_train)\n",
    "\n",
    "# Output the center of each cluster\n",
    "print(f\"Train score after PCA: {knn_pca.score(X_train, y_train):.6f}\")\n",
    "print(f\"Test score after PCA: {knn_pca.score(X_test, y_test):.6f}\")\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=7)\n",
    "cluster_labels = kmeans.fit_predict(digits_data_transformed)\n",
    "\n",
    "# Output the center of each cluster\n",
    "print(\"Center of each cluster (each cluster represents a digit):\")\n",
    "for i, center in enumerate(kmeans.cluster_centers_):\n",
    "    print(f\"Cluster {i}: {center}\")\n",
    "\n",
    "# Determine the mapping between cluster labels and true labels \n",
    "mapped_labels = np.zeros_like(cluster_labels)\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    mask = (cluster_labels == cluster)\n",
    "    mapped_labels[mask] = mode(y[mask])[0]\n",
    "\n",
    "# Calculate and print clustering accuracy\n",
    "print(f\"Clustering Accuracy: {accuracy_score(y, mapped_labels):.6f}\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusionMatrix = confusion_matrix(y, cluster_labels)\n",
    "\n",
    "# Visualize the confusion matrix using matplotlib and the sklearn toolset\n",
    "matrixDisplay = ConfusionMatrixDisplay(confusion_matrix = confusionMatrix)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Create layout and structure figure\n",
    "matrixDisplay.plot(ax = ax, cmap = 'Blues')  # Create Plot\n",
    "# Plot labels\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Clustering Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Visual_Principles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
